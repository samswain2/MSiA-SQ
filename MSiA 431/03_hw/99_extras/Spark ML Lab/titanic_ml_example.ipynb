{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890200ce-e74d-4f97-9f4a-953c14865b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hub.docker.com/r/jupyter/pyspark-notebook\n",
    "# docker pull jupyter/pyspark-notebook\n",
    "# docker run -p 8888:8888 jupyter/pyspark-notebook\n",
    "\n",
    "# The docker run script exposes the container to port 8888\n",
    "\n",
    "# Docker run will output two URLs to access near the bottom of the console output\n",
    "# They look like this: http://127.0.0.1:8888/lab?token={alphanumeric_token}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d407a6-9108-4d1c-a158-d5b91ac928bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"randomSample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1026a0-748f-465f-90ab-02de973421e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_read\n"
     ]
    }
   ],
   "source": [
    "titanic_path = 'titanic_train.csv'\n",
    "titanic = spark.read.csv(titanic_path, header = True)\n",
    "print('file_read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8913da5a-8418-40c5-aecf-10f8f2999695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic = titanic.withColumn(\"Embarked\", \n",
    "                             when(col('Embarked') == '', \"C\")\\\n",
    "                             .otherwise(col('Embarked')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1d74d7-e9bc-4ea0-8955-ca70ac006b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic = titanic.withColumn(\"Age\", titanic[\"Age\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7af4fd-c08a-4742-b5b4-de1f0dc9543d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fill empty ages with the mean age of all passengers, rather than remove the nulls\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age'],\n",
    "    outputCols=[\"new_Age\"]\n",
    ")\n",
    "titanic = imputer.setStrategy(\"mean\").fit(titanic).transform(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee002458-681e-4893-9772-5593f7bdf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Extracting Titles from a String with regex\n",
    "titanic_titles = titanic.withColumn(\"Title\", regexp_replace(col('Name'), '(.*, )|(\\\\..*)', ''))\n",
    "\n",
    "#Create lists of title groups which are uncommon\n",
    "rare_title = ['Dona', 'Lady', 'the Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n",
    "Miss = ['Mlle', 'Ms']\n",
    "\n",
    "#Creating the column\n",
    "titanic_titles = titanic_titles.withColumn(\"Title\", \\\n",
    "                                          when(col('Title').isin(rare_title), \"Rare Title\")\\\n",
    "                                          .when(col('Title').isin(Miss), \"Miss\")\\\n",
    "                                          .when(col('Title') == \"Mme\", \"Mrs\")\\\n",
    "                                          .otherwise(titanic_titles.Title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149783c6-9783-4f22-ace9-c8532f7ac1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_age_bin = titanic_titles.withColumn(\"Child\", \\\n",
    "                                           when(col('new_Age') < 18, \"Child\")\\\n",
    "                                            # when(expr(\"new_Age < 18\"), \"Child\")\n",
    "                                           .otherwise(\"Adult\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030dcc53-67ce-4f6d-9fe2-9d645ba1f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mother, Family Size\n",
    "\n",
    "titanic_mom = titanic_age_bin.withColumn(\"Mother\", \\\n",
    "                                         when(expr(\"Sex == 'female' AND new_Age > 18 AND Parch > 0\"), \"Mother\")\n",
    "#                                            when((col('Sex') == 'female') & (col('Age') > 18) & (col('Parch') > 0), \"Mother\")\\\n",
    "                                           .otherwise(\"Non-Mother\"))\n",
    "\n",
    "titanic_parent = titanic_mom.withColumn(\"A-Parent\", \\\n",
    "                                          when((col('Parch') > 0) & (col('Age')>18), \"A_Parent\")\\\n",
    "                                          .otherwise(\"Non-Parent\"))\n",
    "\n",
    "#Family Sizes\n",
    "titanic_famSize = titanic_parent.withColumn(\"Fsize\", \\\n",
    "                                            col('SibSp') + col('Parch') +1)\n",
    "\n",
    "titanic_f = titanic_famSize.withColumn(\"FsizeD\", \\\n",
    "                                         when(col('Fsize')==1, \"single\")\\\n",
    "                                         .when((col('Fsize') < 5) & (col('Fsize') > 1), \"medium\")\\\n",
    "                                         .otherwise(\"large\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91aed41c-4ede-43ce-94ce-2eccfa85f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with transformations\n"
     ]
    }
   ],
   "source": [
    "#Dataset from before any indexing or encoding happened\n",
    "titanic_final = titanic_f.select(\"Survived\", \"Pclass\", \"Sex\", \"new_Age\", \"A-Parent\", \"FsizeD\", \"Title\")\n",
    "print('done with transformations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2442cb4-c00f-43d0-8989-6dda12757a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model transformed\n"
     ]
    }
   ],
   "source": [
    "classIdxer = StringIndexer(inputCol='Pclass',outputCol='PclassIdx')\n",
    "sexIdxer = StringIndexer(inputCol='Sex',outputCol='SexIdx')\n",
    "parentIdxer = StringIndexer(inputCol='A-Parent',outputCol='A-ParentIdx')\n",
    "FsizeIdxer = StringIndexer(inputCol='FsizeD',outputCol='FsizeDIdx')\n",
    "titleIdxer = StringIndexer(inputCol='Title',outputCol='TitleIdx')\n",
    "\n",
    "survivedIdxer = StringIndexer(inputCol=\"Survived\", outputCol=\"SurvivedIdx\")\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=[\"PclassIdx\", \"SexIdx\", \"A-ParentIdx\", \"FsizeDIdx\", \"TitleIdx\"], outputCols=[\"Pclassvec\", \"Sexvec\", \"A-Parentvec\", \"FsizeDvec\", \"Titlevec\"]).setHandleInvalid(\"keep\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [\"Pclassvec\", \"Sexvec\", \"new_Age\", \"A-Parentvec\", \"FsizeDvec\", \"Titlevec\"], outputCol = 'features')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"SurvivedIdx\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages = [classIdxer, sexIdxer, parentIdxer, FsizeIdxer, titleIdxer, survivedIdxer, encoder, assembler, rf])\n",
    "\n",
    "train, test = titanic_final.randomSplit([0.75, 0.25])\n",
    "\n",
    "model = pipeline.fit(train)\n",
    "predictions = model.transform(test)\n",
    "print('model transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae680bb9-7437-4e16-8722-99324b7ebe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.184466\n"
     ]
    }
   ],
   "source": [
    "predictions2 = predictions.select(col(\"Survived\").cast(\"Float\"),col(\"prediction\"))\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions2)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994fa418-5c99-4b90-b1fc-97666d6c1188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.createOrReplaceTempView(\"Predictions\")\n",
    "predictions_sql = spark.sql(\"select sum(case when SurvivedIdx = prediction then 1 else 0 end) / count(prediction) as Accuracy from Predictions\")\n",
    "\n",
    "with open('titanic_accuracy.txt', 'w') as file:\n",
    "    for item in predictions_sql.collect():\n",
    "        file.write(str(item))\n",
    "\n",
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
