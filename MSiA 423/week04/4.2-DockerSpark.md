#----------------------------------
#Docker PySpark Jupyter Container
#----------------------------------

#Step1: Download Spark notebook image  
docker pull jupyter/pyspark-notebook

#Step2: Create and run a spark notebook container		
docker run --name "sparknb" -it -p 8888:8888 -p 4040:4040 jupyter/pyspark-notebook

#Step3: Navigate to Notebook URL from Docker logs
#http://localhost:8888/tree

#Step4: Copy data from localhost into container		
docker cp <local-path>\data.csv sparknb:/home/jovyan/work

#Run bash command line inside container
#Use a different Docker terminal window
docker exec -i -t sparknb /bin/bash

#list files inside container bash
ls

#create or upload a new Jupyter notebook

from pyspark import SparkContext, SparkConf
from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .appName("SparkTest") \
    .getOrCreate()

spark.sparkContext.getConf().getAll()
    
df = spark.read.csv("data.csv", header=True)
df.show(5)